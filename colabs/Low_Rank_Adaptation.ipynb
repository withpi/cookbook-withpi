{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/Low_Rank_Adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://withpi.ai\"><img src=\"https://withpi.ai/logoFullBlack.svg\" width=\"240\"></a>\n",
        "\n",
        "<a href=\"https://code.withpi.ai\"><font size=\"4\">Documentation</font></a>\n",
        "\n",
        "<a href=\"https://play.withpi.ai\"><font size=\"4\">Technique Catalog</font></a>"
      ],
      "metadata": {
        "id": "pi-masthead"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwm4tjdnedp6"
      },
      "source": [
        "# WithPi Contract Creation\n",
        "\n",
        "You have a generative AI application, but you aren't happy with its responses to user prompts.  The **WithPi** SDK helps you build a feedback loop, making your responses get better automatically without significant Quality expertise.  Let's dig in!\n",
        "\n",
        "This Colab walks you through the first step, creating a **Pi Contract**.  This is a **human and machine readable** description of what **goodness** means to you and is the cornerstone of our approach.\n",
        "\n",
        "This should take about **15 minutes**, even if you're unfamiliar with Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and initialize SDK\n",
        "\n",
        "Connect to a regular CPU Python 3 runtime.  You won't need GPUs for this notebook.\n",
        "\n",
        "You'll need a WITHPI_API_KEY from https://play.withpi.ai.  Add it to your notebook secrets (the key symbol) on the left.\n",
        "\n",
        "Run the cell below to install packages and load the SDK"
      ],
      "metadata": {
        "id": "pi-setup-markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi-setup"
      },
      "outputs": [],
      "execution_count": null,
      "source": [
        "%%capture\n",
        "\n",
        "%pip install withpi litellm\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from litellm import completion\n",
        "from withpi import PiClient\n",
        "\n",
        "os.environ[\"WITHPI_API_KEY\"] = userdata.get('WITHPI_API_KEY')\n",
        "\n",
        "client = PiClient()\n",
        "\n",
        "def print_contract(contract):\n",
        "  for dimension in contract.dimensions:\n    print(dimension.label)\n",
        "  for sub_dimension in dimension.sub_dimensions:\n",
        "    print(f\"\\t{sub_dimension.description}\")\n",
        "\n",
        "def generate(system: str, user: str, model: str) -> str:\n",
        "  messages = [\n",
        "    {\n",
        "      \"content\": system,\n",
        "      \"role\": \"system\"\n",
        "    },\n",
        "    {\n",
        "      \"content\": prompt,\n",
        "      \"role\": \"user\"\n",
        "    }\n",
        "  ]\n",
        "  return completion(model=model,\n",
        "                    messages=messages).choices[0].message.content\n",
        "\n",
        "class printer(str):\n",
        "  def __repr__(self):\n",
        "    return self\n",
        "def prettyprint(response: str):\n",
        "  display(printer(response))\n",
        "\n",
        "def print_scores(pi_scores):\n",
        "  for dimension_name, dimension_scores in pi_scores.dimension_scores.items():\n",
        "    print(f\"{dimension_name}: {dimension_scores.total_score}\")\n",
        "    for subdimension_name, subdimension_score in dimension_scores.subdimension_scores.items():\n",
        "      print(f\"\\t{subdimension_name}: {subdimension_score}\")\n",
        "    print(\"\\n\")\n",
        "  print(\"---------------------\")\n",
        "  print(f\"Total score: {pi_scores.total_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7RRO3iXjYbY"
      },
      "source": [
        "# Make a contract\n",
        "\n",
        "Let's say you want to build an application that generates children's stories teaching a life lesson.  Call it `AesopAI`.\n",
        "\n",
        "Start by creating a first cut contract based on that general input, proposed in the following cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXJmb89i5iN5"
      },
      "outputs": [],
      "source": [
        "aesop_contract = client.contracts.generate_dimensions(\n",
        "    contract_description=(\n",
        "        \"Write a children's story in the style of Aesop's Fables \"\n",
        "        \"teaching a life lesson specified by the user. Provide just the \"\n",
        "        \"story with no extra content.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "for dimension in aesop_contract.dimensions:\n",
        "  print(dimension.label)\n",
        "  for sub_dimension in dimension.sub_dimensions:\n",
        "    print(f\"\\t{sub_dimension.description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4eChTjc66_f"
      },
      "source": [
        "A contract is essentially a hierarchical rubric for grading a response.  A bunch of \"simple\" questions add up to broader categories, which yield a final score.  Output will vary somewhat, but the table above should have reasonable grading questions for the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FAoBqU7dwf"
      },
      "source": [
        "## Smoke test the contract\n",
        "\n",
        "Let's see how it performs with no further tuning.  The below cell uses Gemini to generate a response, but any suitable model will work fine.\n",
        "\n",
        "Adjust to pick a different model and supply your own key with docs at https://docs.litellm.ai/docs/.\n",
        "\n",
        "You can import a Google Gemini key from AI Studio on the left pane, which populates a GOOGLE_API_KEY secret essentially for free."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhJrCijJ8I2n"
      },
      "outputs": [],
      "source": [
        "from litellm import completion\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "def generate(prompt: str) -> str:\n",
        "  messages = [\n",
        "      {\n",
        "          \"content\": aesop_contract.description,\n",
        "          \"role\": \"system\"\n",
        "      },\n",
        "      {\n",
        "          \"content\": prompt,\n",
        "          \"role\": \"user\"\n",
        "      },\n",
        "  ]\n",
        "  return completion(model=\"gemini/gemini-2.0-flash-exp\",\n",
        "                    messages=messages).choices[0].message.content\n",
        "\n",
        "prompt = \"The importance of sharing\"\n",
        "response = generate(prompt)\n",
        "\n",
        "# Print with line wrapping and explicit newlines.\n",
        "class printer(str):\n",
        "    def __repr__(self):\n",
        "       return self\n",
        "display(printer(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU0TJGzFk-2C"
      },
      "source": [
        "## Score it!\n",
        "\n",
        "Take the generated response and see how it scores with Pi.\n",
        "\n",
        "The below cell will run Pi Scoring, evaluating each dimension in the contract, offering a score from 1 (excellent!) to 0 (terrible!).  The current contract is **uncalibrated**, meaning that all the dimensions are equally important, but it's a starting point for learning which are **actually** imporant based on your preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NpCZhP6exgI"
      },
      "outputs": [],
      "source": [
        "pi_scores = client.contracts.score(\n",
        "    contract=aesop_contract,\n",
        "    llm_input=prompt,\n",
        "    llm_output=response,\n",
        ")\n",
        "\n",
        "for dimension_name, dimension_scores in pi_scores.dimension_scores.items():\n",
        "  print(f\"{dimension_name}: {dimension_scores.total_score}\")\n",
        "  for subdimension_name, subdimension_score in dimension_scores.subdimension_scores.items():\n",
        "    print(f\"\\t{subdimension_name}: {subdimension_score}\")\n",
        "  print(\"\\n\")\n",
        "print(\"---------------------\")\n",
        "print(f\"Total score: {pi_scores.total_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9UOAOSQn1bF"
      },
      "source": [
        "## Save it!\n",
        "\n",
        "Finally, save the Contract so you can come back to it later.\n",
        "\n",
        "A contract is a simple Pydantic model, which can be serialized to JSON and stored locally.\n",
        "\n",
        "The cell below will offer a download of the contract.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPlsGumImqm1"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "filename = 'aesop_ai.json'\n",
        "Path(filename).write_text(aesop_contract.model_dump_json(indent=2))\n",
        "files.download(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT7s_nuJsHbM"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that you have a basic scorer, you want an input set to play with. Proceed to [InputSet Generation](https://colab.research.google.com/github/withpi/cookbook-withpi/blob/main/colabs/InputSet_Generation.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}